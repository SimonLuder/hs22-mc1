{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa6f718f-41c0-4870-ac87-dcdc8367afe7",
   "metadata": {},
   "source": [
    "# HPC Minichallenge 1 - HS22"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d436de23-3d95-4217-8d11-97983dc197b2",
   "metadata": {},
   "source": [
    "## Teil 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b93bf3-2fca-4b58-848f-93f7efd1a2d0",
   "metadata": {},
   "source": [
    "### Aufgabe 1.4\n",
    "\n",
    "In Kafka wird primär über vordefinierte Schnittstellen (Producer / Consumer) kommuniziert. Nutzer organisieren ihre Daten hierbei innerhalb von Topics. Kafka erlaubt es beim Erstellen neuer Topics die Anzahl an Partitionen als auch den Replikationsfaktor zu definieren. Der Replikationsfaktor bestimmt herbei, wie oft die Daten auf den verfügbaren Nodes dupliziert werden. Die Anzahl an Partitionen sind relevant, wenn es um die Parallelisierbarkeit der Schnittstellen geht.  Die genaue Verteilung der Daten in den Partitionen als auch die Aufteilung der Partitionen in einzelne Nodes organisiert Kafka eigenständig. Beim Monitoring via Kafdrop ist für jede Partition die Leader Node ersichtlich als auch die Priorität der Replikation Nodes. Das Abschalten einzelner Docker Container hat keinen grösseren Einfluss auf die Funktionsfähigkeit von Kafka, sofern der Replikationsfaktor genügend hoch gewählt ist. Solange mindestens eine Replikation in Kafka aktiv ist, ist es möglich weiterhin Informationen zu schreiben und abzugreifen. Der Kafka Zookeeper vergibt automatisch die ausgefallenen Leader auf die verfügbaren Replikation Nodes. Werden nun Partitionen auf Nodes durch das Wiedereinschalten von Containern erneut verfügbar, bleiben diese scheinbar als Leader Nodes disqualifiziert. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c1a893-dea3-4ba6-9b9d-cf91a168b287",
   "metadata": {},
   "source": [
    "### Aufgabe 1.7\n",
    "\n",
    "\n",
    "#### Daten: \n",
    "Die live Bewertungen werden durch den bestehenden Datensatz **Toys_and_Games_5.json** simuliert. Dieses ist einem Subset des Amazon Review Dataset von Ni Jianmo welches unter dem folgenden URL erreichbar ist: \n",
    "https://nijianmo.github.io/amazon/index.html\n",
    "\n",
    "#### Scenario: \n",
    "Ein Onlinehändler möchte auf seiner Webseite neu ein Live-Feed implementieren, mit dem Ziel, die Kunden dazu zu ermutigen mehr Produkte anzusehen. Dafür sollen im Live-Feed jeweils die fünf trendigen Produkte der letzten Minute mit den aktuellsten Kundenratings angezeigt werden. \n",
    "Für die Umsetzung möchte er die bereits bestehende Datenmanagement-Infrastruktur nutzen, in dem Ratings mittels Apache Kafka strukturiert werden. \n",
    "Diese ist in *Abbildung 1* aufgeführt.\n",
    "\n",
    "![Schema_1.png](Schema_1.png)\n",
    "\n",
    "#### Struktur:\n",
    "\n",
    "Das Kafka Environment ist auf verschiedene Images verteilt. Dieses beinhaltet das Kafka Cluster bestehend aus den drei Broker images *broker1*, *broker2* und *broker3*, als auch dem Zookeper *zookeper*, welcher die Kommunikation und Datenstrukturierung unter den Broker organisiert und in einem separaten Image läuft. Als zusätzlicher Mikroservice fürs Monitoring steht, das Kafdrop web UI zur Verfügung, welches über ein weiteres image *kafdrop1* ausgeführt wird.\n",
    "\n",
    "Im *jupyter1* Container wird sämtlicher in Python geschriebener Code ausgeführt.\n",
    "Hier befinden sich auch die vier Notebooks, von welchen der gesammte Prozess gesteuert werden kann.\n",
    "\n",
    "- **Producer_1.ipynb** simuliert die live Bewertungen der Kunden. Hierfür werden mit einer definierbaren Frequenz > 1 Hz einzelne Bewertungen aus dem Toys_and_Games_5.json gelesen und zu Kafka unter dem Topic `live_ratings` gesendet. \n",
    "\n",
    "- **Consumer_1.ipynb** erhält alle live Bewertungen, welche auf Kafka unter dem Topic  `live_ratings` publiziert wurden. In Kombination mit einem Datasink werden in minütlichen Abständen die Anzahl an Bewertungen pro Produkt als auch die durchschnittliche Produktbewertung errechnet und abgespeichert.\n",
    "\n",
    "- **Producer_2.ipynb** überprüft, ob neue Durchschnittsbewertungen vorhanden sind und publiziert jeweils die fünf Produkte mit den häufigsten Bewertungen auf ein neues Kafka Topic `top_ratings`.\n",
    "\n",
    "- **Consumer_2.ipynb** erhält die fünf  meist bewerteten Produkte aus dem Topic `top_ratings` und zeigt diese live als Barplot an.\n",
    "\n",
    "#### Verbesserungespotential\n",
    "\n",
    "Zukünftig können die einzelnen Scripts auf mehrere Container verteilt werden. Dadurch wäre es möglich, diese auf unterschiedliche Systeme laufen zu lassen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f77cc0-63b4-4d46-ade4-adf522f0a567",
   "metadata": {},
   "source": [
    "### 1. Bonusaufgabe:\n",
    "\n",
    "To do..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e04abe-d964-42ce-a7b8-fbd60f06e48f",
   "metadata": {},
   "source": [
    "## Teil 2\n",
    "\n",
    "### Aufgabe 2.1\n",
    "\n",
    "In diesem Schritt wird RabbitMQ als weiterer Message Broker hinzugefügt. \n",
    "\n",
    "Dafür wurde in einem ersten Schritt das **docker-compose.yml** angepasst. Hier wurde ein neuer Container *rabbitmq1* erstellt, welcher das rabbitmq:3.8-management-alpine image von docker-hub herunterlädt. Der Zusatz \"Management\" bedeutet hier, dass wir über einen zusätzlichen Port automatisch ein UI mitgeliefert erhalten, welches zum Monitoren verwendet werden kann. Dieses ist via [localhost:15672](localhost:15672) erreichbar\n",
    "\n",
    "\"Alpine\" bedeute hingegen legidlich, dass es sich um die speichereffiziente Variante handelt.\n",
    "\n",
    "Weiter wurden die bestehenden Klassen und ihre Methoden im **helper_file.py** angepasst und erweitert, sodass nun einfach zwischen Kafka und RabbitMQ gewechselt werden kann."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29b53e6-75dd-4f9b-9149-584e30c0572c",
   "metadata": {},
   "source": [
    "### Aufgabe 2.2\n",
    "\n",
    "Nachfolgend in Visualisierung 2 ist nun die Implementation des Message Brokers mittels RabbitMQ visualisiert. \n",
    "\n",
    "![Schema_2.png](Schema_2.png)\n",
    "\n",
    "\n",
    "Anders als bei der Implementation mit Kafka wird hier aktuell nur ein Container genutzt, über welchen das ganze System läuft. Es ist jedoch auch mit RabbitMQ möglich ein Cluster mit mehreren Containern zu erstellen. Der *jupyter1* Container bleibt im Vergleich zur vorherigen Implementation unverändert. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b598c1d8-2d6a-4dd3-82bf-c7485f4cc22a",
   "metadata": {},
   "source": [
    "### Aufgabe 2.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad9f58d-8eab-4ba2-b685-c44e4d616e90",
   "metadata": {},
   "source": [
    "RabbitMQ kommuniziert standardmässig mit dem binären AMQP-0.9.1 Protokoll, wobei auch noch andere Protokolle unterstützt werden. Siehe [www.rabbitmq.com/protocols](https://www.rabbitmq.com/protocols.html#:~:text=AMQP%200%2D9%2D1%20is%20the,protocol%20used%20by%20RabbitMQ%20tutorials) \n",
    "\n",
    "RabbitMQ selbst funktioniert als pub-sub Kommunikationspattern. Die Daten werden beim publishen mit RabbitMQ zuerst auf eine Exchange gesendet, wobei es mehrere Arten von Exchanges gibt. Ich nutze den Exchange-Typ `Direkt`, was bedeutet, dass unter Verwendung eines Message-Routing-Schlüssel Nachrichten von der Exchange kopiert und die Kopien direkt zu einer Queue hinzugefügt werden.\n",
    "\n",
    "Alternative Exchange-Typen wären:\n",
    "- `Topic`: Hier werden Nachrichten basierend auf sub-strings einer oder auch mehreren Queues zugeordnet. Dabei muss die Queue gleich heissen wie der relevante Sub-string.\n",
    "\n",
    "- `Fanout`: Verteilt alle Nachrichten an alle an eine Exchange gebundene Exchange. Der Message-Routing-Schlüssel wird hier ignoriert.\n",
    "\n",
    "- `Header`: Gleich wie Topic, aber anstelle des Message-Routing-Schlüssels werden hier Informationen aus dem Header der Nachricht fürs Routing verwendet. \n",
    "\n",
    "Anschliessend können die Queues über den passenden Message-Routing-Schlüssel wieder abgerufen werden. Wird vom Nutzer keine Exchange definiert, wird standardmässig eine immer vorhandene Standard-Exchange `\"\"` verwendet.\n",
    "\n",
    "#### Kafka vs RabbitMQ\n",
    "Da RabbitMQ mit Queues arbeitet, werden Nachrichten, nachdem sie konsumiert wurden und eine Bestätigung zum Konsum gesendet wurde, auch tatsächlich gelöscht. Kafka hingegen kann auch als Queue genutzt werden, die dahinterliegende Speicherarchitektur ist jedoch deutlich flexibler und die Lebensdauer von Daten in Kafka wird durch eine Policy festgelegt. Während Kafka mit dem Zookeeper einen grossen Teil der Speicherverwaltung selbst übernimmt, kann bei RabbitMQ das exakte Datenrouting in der Applikation festgelegt werden, als auch Prioritäten im Datenfluss definiert werden.\n",
    "\n",
    "\n",
    "\n",
    "#### Weitere Kommunikationsarten: \n",
    "*System-to-system*: Hierbei handelt es sich um einen traditionellen Ansatz, in dem kein weiterer Message-Broker dazwischen fungiert. Zwar bietet diese Methode für kleine Systeme mit nur sehr wenigen Akteuren an. Sie ist jedoch erstens relativ langsam, da der Sender nicht mehr Daten produzieren sollte als Empfänger verarbeiten kann, da sonst Datenverlust droht. Und zweitens ist diese Variante nur schlecht skalierbar, da für jeden weiteren Akteur im Netz eigene Schnittstellen programmiert werden müssen, was schnell exponentiell Skaliert.\n",
    "\n",
    "#### Praktikabilität des Kommunikationspattern \n",
    "Ich bin der Meinung, dass das gewöhnliche pup-sub Kommunikationspattern mit RabbitMQ nur teilweise geeignet ist, da die Ratings nach dem Konsum gelöscht werden und vom Webshop ein Interesse bestehen sollte, Produktbewertungen Persistent aufzubewahren. In diesem Falle wäre also die Verwendung von Kafka als Message-Broker definitiv sinnvoller. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2a97bd-5eac-43bc-bcfc-d57de2c887cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
